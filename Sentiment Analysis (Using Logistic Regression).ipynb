{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125353da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the relevant libraries\n",
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random                              # pseudo-random number generator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f398b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to C:\\Users\\MOHAMMED\n",
      "[nltk_data]     USAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloads sample twitter dataset.\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a56a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting up all functions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks    \n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    " \n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "# Functions to convert data into suitable form\n",
    "def extract_features(tweet):\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    x[0,0] = 1 \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in tweet:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word,1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "        \n",
    "    return np.array([x[0,1],x[0,2]])\n",
    "\n",
    "\n",
    "\n",
    "def token_splitter_pos(a):\n",
    "    return a[0]\n",
    "\n",
    "def token_splitter_neg(a):\n",
    "    return a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dd2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  8000\n",
      "Number of tweets:  2000\n"
     ]
    }
   ],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "train_pos  = all_positive_tweets[:4000]\n",
    "train_neg  = all_negative_tweets[:4000]\n",
    "\n",
    "test_pos  = all_positive_tweets[4000:]\n",
    "test_neg  = all_negative_tweets[4000:]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg \n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos))), np.zeros((len(train_neg))))\n",
    "test_y = np.append(np.ones((len(test_pos))), np.zeros((len(test_neg))))\n",
    "\n",
    "print(\"Number of tweets: \", len(train_x))\n",
    "print(\"Number of tweets: \", len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbc71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76142ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(train_x)\n",
    "train_x.rename(columns = {0:'Tweet'}, inplace = True)\n",
    "train_x['Tweet_arrayed'] = train_x['Tweet'].apply(process_tweet)\n",
    "\n",
    "test_x = pd.DataFrame(test_x)\n",
    "test_x.rename(columns = {0:'Tweet'}, inplace = True)\n",
    "test_x['Tweet_arrayed'] = test_x['Tweet'].apply(process_tweet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e520e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_arrayed</th>\n",
       "      <th>Tweet_tokenised</th>\n",
       "      <th>bias</th>\n",
       "      <th>postive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>[followfriday, top, engag, member, commun, wee...</td>\n",
       "      <td>[3133.0, 61.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3133.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>[hey, jame, odd, :/, pleas, call, contact, cen...</td>\n",
       "      <td>[3705.0, 444.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3705.0</td>\n",
       "      <td>444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>[listen, last, night, :), bleed, amaz, track, ...</td>\n",
       "      <td>[3119.0, 116.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3119.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>[congrat, :)]</td>\n",
       "      <td>[2975.0, 4.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>[yeaaah, yipppi, accnt, verifi, rqst, succeed,...</td>\n",
       "      <td>[3232.0, 226.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>Amelia didnt stalk my twitter :(</td>\n",
       "      <td>[amelia, didnt, stalk, twitter, :(]</td>\n",
       "      <td>[29.0, 3718.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>oh, i missed the broadcast. : (</td>\n",
       "      <td>[oh, miss, broadcast]</td>\n",
       "      <td>[62.0, 323.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>i really can't stream on melon i feel useless :-(</td>\n",
       "      <td>[realli, can't, stream, melon, feel, useless, ...</td>\n",
       "      <td>[144.0, 793.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>I need to stop looking at old soccer pictures :(</td>\n",
       "      <td>[need, stop, look, old, soccer, pictur, :(]</td>\n",
       "      <td>[207.0, 3902.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>207.0</td>\n",
       "      <td>3902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Got an interview for the job that I want but t...</td>\n",
       "      <td>[got, interview, job, want, rang, tuesday, int...</td>\n",
       "      <td>[191.0, 3986.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>191.0</td>\n",
       "      <td>3986.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "0     #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1     @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2     @DespiteOfficial we had a listen last night :)...   \n",
       "3                                  @97sides CONGRATS :)   \n",
       "4     yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "...                                                 ...   \n",
       "7995                   Amelia didnt stalk my twitter :(   \n",
       "7996                    oh, i missed the broadcast. : (   \n",
       "7997  i really can't stream on melon i feel useless :-(   \n",
       "7998   I need to stop looking at old soccer pictures :(   \n",
       "7999  Got an interview for the job that I want but t...   \n",
       "\n",
       "                                          Tweet_arrayed  Tweet_tokenised  \\\n",
       "0     [followfriday, top, engag, member, commun, wee...   [3133.0, 61.0]   \n",
       "1     [hey, jame, odd, :/, pleas, call, contact, cen...  [3705.0, 444.0]   \n",
       "2     [listen, last, night, :), bleed, amaz, track, ...  [3119.0, 116.0]   \n",
       "3                                         [congrat, :)]    [2975.0, 4.0]   \n",
       "4     [yeaaah, yipppi, accnt, verifi, rqst, succeed,...  [3232.0, 226.0]   \n",
       "...                                                 ...              ...   \n",
       "7995                [amelia, didnt, stalk, twitter, :(]   [29.0, 3718.0]   \n",
       "7996                              [oh, miss, broadcast]    [62.0, 323.0]   \n",
       "7997  [realli, can't, stream, melon, feel, useless, ...   [144.0, 793.0]   \n",
       "7998        [need, stop, look, old, soccer, pictur, :(]  [207.0, 3902.0]   \n",
       "7999  [got, interview, job, want, rang, tuesday, int...  [191.0, 3986.0]   \n",
       "\n",
       "      bias  postive  negative  \n",
       "0        1   3133.0      61.0  \n",
       "1        1   3705.0     444.0  \n",
       "2        1   3119.0     116.0  \n",
       "3        1   2975.0       4.0  \n",
       "4        1   3232.0     226.0  \n",
       "...    ...      ...       ...  \n",
       "7995     1     29.0    3718.0  \n",
       "7996     1     62.0     323.0  \n",
       "7997     1    144.0     793.0  \n",
       "7998     1    207.0    3902.0  \n",
       "7999     1    191.0    3986.0  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['Tweet_tokenised'] = train_x['Tweet_arrayed'].apply(extract_features)\n",
    "train_x['bias']=1\n",
    "train_x['postive'] = train_x['Tweet_tokenised'].apply(token_splitter_pos)\n",
    "train_x['negative'] = train_x['Tweet_tokenised'].apply(token_splitter_neg)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c88455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_arrayed</th>\n",
       "      <th>Tweet_tokenised</th>\n",
       "      <th>bias</th>\n",
       "      <th>postive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bro:U wan cut hair anot,ur hair long Liao bo\\n...</td>\n",
       "      <td>[bro, u, wan, cut, hair, anot, ur, hair, long,...</td>\n",
       "      <td>[3397.0, 414.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3397.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@heyclaireee is back! thnx God!!! i'm so happy :)</td>\n",
       "      <td>[back, thnx, god, i'm, happi, :)]</td>\n",
       "      <td>[3415.0, 397.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3415.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BBCRadio3 thought it was my ears which were m...</td>\n",
       "      <td>[thought, ear, malfunct, thank, good, clear, o...</td>\n",
       "      <td>[1392.0, 329.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@HumayAG 'Stuck in the centre right with you. ...</td>\n",
       "      <td>[stuck, centr, right, clown, right, joker, lef...</td>\n",
       "      <td>[3280.0, 401.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy Friday :-) http://t.co/iymPIlWXFY</td>\n",
       "      <td>[happi, friday, :-)]</td>\n",
       "      <td>[805.0, 27.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>805.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I wanna change my avi but uSanele :(</td>\n",
       "      <td>[wanna, chang, avi, usanel, :(]</td>\n",
       "      <td>[45.0, 3776.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>MY PUPPY BROKE HER FOOT :(</td>\n",
       "      <td>[puppi, broke, foot, :(]</td>\n",
       "      <td>[3.0, 3686.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>where's all the jaebum baby pictures :((</td>\n",
       "      <td>[where', jaebum, babi, pictur, :(]</td>\n",
       "      <td>[26.0, 3729.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>But but Mr Ahmad Maslan cooks too :( https://t...</td>\n",
       "      <td>[mr, ahmad, maslan, cook, :(]</td>\n",
       "      <td>[7.0, 3684.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>@eawoman As a Hull supporter I am expecting a ...</td>\n",
       "      <td>[hull, support, expect, misser, week, :-(]</td>\n",
       "      <td>[100.0, 461.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "0     Bro:U wan cut hair anot,ur hair long Liao bo\\n...   \n",
       "1     @heyclaireee is back! thnx God!!! i'm so happy :)   \n",
       "2     @BBCRadio3 thought it was my ears which were m...   \n",
       "3     @HumayAG 'Stuck in the centre right with you. ...   \n",
       "4               Happy Friday :-) http://t.co/iymPIlWXFY   \n",
       "...                                                 ...   \n",
       "1995               I wanna change my avi but uSanele :(   \n",
       "1996                         MY PUPPY BROKE HER FOOT :(   \n",
       "1997           where's all the jaebum baby pictures :((   \n",
       "1998  But but Mr Ahmad Maslan cooks too :( https://t...   \n",
       "1999  @eawoman As a Hull supporter I am expecting a ...   \n",
       "\n",
       "                                          Tweet_arrayed  Tweet_tokenised  \\\n",
       "0     [bro, u, wan, cut, hair, anot, ur, hair, long,...  [3397.0, 414.0]   \n",
       "1                     [back, thnx, god, i'm, happi, :)]  [3415.0, 397.0]   \n",
       "2     [thought, ear, malfunct, thank, good, clear, o...  [1392.0, 329.0]   \n",
       "3     [stuck, centr, right, clown, right, joker, lef...  [3280.0, 401.0]   \n",
       "4                                  [happi, friday, :-)]    [805.0, 27.0]   \n",
       "...                                                 ...              ...   \n",
       "1995                    [wanna, chang, avi, usanel, :(]   [45.0, 3776.0]   \n",
       "1996                           [puppi, broke, foot, :(]    [3.0, 3686.0]   \n",
       "1997                 [where', jaebum, babi, pictur, :(]   [26.0, 3729.0]   \n",
       "1998                      [mr, ahmad, maslan, cook, :(]    [7.0, 3684.0]   \n",
       "1999         [hull, support, expect, misser, week, :-(]   [100.0, 461.0]   \n",
       "\n",
       "      bias  postive  negative  \n",
       "0        1   3397.0     414.0  \n",
       "1        1   3415.0     397.0  \n",
       "2        1   1392.0     329.0  \n",
       "3        1   3280.0     401.0  \n",
       "4        1    805.0      27.0  \n",
       "...    ...      ...       ...  \n",
       "1995     1     45.0    3776.0  \n",
       "1996     1      3.0    3686.0  \n",
       "1997     1     26.0    3729.0  \n",
       "1998     1      7.0    3684.0  \n",
       "1999     1    100.0     461.0  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x['Tweet_tokenised'] = test_x['Tweet_arrayed'].apply(extract_features)\n",
    "test_x['bias']=1\n",
    "test_x['postive'] = test_x['Tweet_tokenised'].apply(token_splitter_pos)\n",
    "test_x['negative'] = test_x['Tweet_tokenised'].apply(token_splitter_neg)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb67e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_x[['bias', 'postive','negative']].values\n",
    "y_train = train_y\n",
    "X_test = test_x[['bias', 'postive','negative']].values\n",
    "y_test = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc8505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[993   7]\n",
      " [  5 995]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      1000\n",
      "         1.0       0.99      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a23f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
